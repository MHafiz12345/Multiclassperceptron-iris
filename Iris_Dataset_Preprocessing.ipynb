{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3-rXKD1PMYR",
        "outputId": "84e87ffc-5043-4e93-90d5-b80ecb402570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive, files\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Load the Iris dataset**"
      ],
      "metadata": {
        "id": "7LB8AyapBiNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data = pd.read_csv('drive/My Drive/irisdataset.csv')\n",
        "print(\"Original dataset shape:\", iris_data.shape)"
      ],
      "metadata": {
        "id": "NwuOfwmWPOdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454d20c7-9d80-4bf6-cfc3-07364be0c347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Step 2: Data Quality Checks**"
      ],
      "metadata": {
        "id": "0sulLXZfW2Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = {column: iris_data[column].isna().sum() for column in iris_data.columns}\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXUpuhzSW5zm",
        "outputId": "b4f76af3-e0de-4826-9716-5ae2541a7f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "{'sepal.length': np.int64(0), 'sepal.width': np.int64(0), 'petal.length': np.int64(0), 'petal.width': np.int64(0), 'variety': np.int64(0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate rows\n",
        "duplicate_rows = iris_data.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")\n",
        "\n",
        "# If duplicates exist, show them\n",
        "if duplicate_rows > 0:\n",
        "    print(\"\\nDuplicate rows:\")\n",
        "    print(iris_data[iris_data.duplicated(keep='first')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4TUJzC3XDYB",
        "outputId": "80c20b87-7a22-4df6-bf16-d6eeb60222c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of duplicate rows: 1\n",
            "\n",
            "Duplicate rows:\n",
            "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
            "142           5.8          2.7           5.1          1.9  Virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates and keep first occurrence\n",
        "iris_data_clean = iris_data.drop_duplicates(keep='first')\n",
        "print(\"\\nDataset shape after removing duplicates:\", iris_data_clean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUTVleMsY-Zg",
        "outputId": "00525848-43b2-44f0-c6c8-0240472acfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset shape after removing duplicates: (149, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LOFt0RIOZ1To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Feature Selection**"
      ],
      "metadata": {
        "id": "ae2PJB8IBvhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['sepal.length', 'sepal.width', 'petal.length', 'petal.width']\n",
        "X = iris_data[features].values  # Convert to numpy array for easier manipulation\n",
        "y = iris_data['variety']"
      ],
      "metadata": {
        "id": "_FPbJ9UBBvHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Step 4: Label Encoding**"
      ],
      "metadata": {
        "id": "Z_tJ1Cm0BzhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique classes and create mapping\n",
        "unique_classes = np.unique(y)\n",
        "class_to_index = {class_name: index for index, class_name in enumerate(unique_classes)}\n",
        "print(\"\\nClass encoding mapping:\")\n",
        "print(class_to_index)\n",
        "\n",
        "# Apply manual encoding\n",
        "y_encoded = np.array([class_to_index[class_name] for class_name in y])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnRzaFjCB58o",
        "outputId": "243af0e0-1023-4a75-8979-8f7580812c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class encoding mapping:\n",
            "{'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Z-score Standardization**"
      ],
      "metadata": {
        "id": "xeKCvZEoCFhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and standard deviation for each feature\n",
        "feature_means = np.mean(X, axis=0)\n",
        "feature_stds = np.std(X, axis=0)\n",
        "\n",
        "# Apply Z-score standardization manually\n",
        "X_scaled = np.zeros_like(X, dtype=float)\n",
        "for i in range(X.shape[1]):\n",
        "    X_scaled[:, i] = (X[:, i] - feature_means[i]) / feature_stds[i]\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
        "\n",
        "# Verify standardization\n",
        "print(\"\\nManual verification of standardization:\")\n",
        "print(\"Feature means after standardization:\")\n",
        "print(np.mean(X_scaled, axis=0))\n",
        "print(\"\\nFeature standard deviations after standardization:\")\n",
        "print(np.std(X_scaled, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arsz7QORCHaQ",
        "outputId": "646dc74a-8383-494e-ed42-773a6d877a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Manual verification of standardization:\n",
            "Feature means after standardization:\n",
            "[-4.73695157e-16 -7.81597009e-16 -4.26325641e-16 -4.73695157e-16]\n",
            "\n",
            "Feature standard deviations after standardization:\n",
            "[1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Step 6: Combine processed features and target**"
      ],
      "metadata": {
        "id": "lYOPpq8JXe1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = X_scaled_df.copy()\n",
        "processed_data['target'] = y_encoded\n",
        "processed_data['variety'] = y  # Keep original labels for reference\n",
        "\n",
        "print(\"\\nFinal preprocessed data:\")\n",
        "print(processed_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb67u0d2X05J",
        "outputId": "ec6b455a-2753-4534-dc4b-44a483b32b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final preprocessed data:\n",
            "   sepal.length  sepal.width  petal.length  petal.width  target variety\n",
            "0     -0.900681     1.019004     -1.340227    -1.315444       0  Setosa\n",
            "1     -1.143017    -0.131979     -1.340227    -1.315444       0  Setosa\n",
            "2     -1.385353     0.328414     -1.397064    -1.315444       0  Setosa\n",
            "3     -1.506521     0.098217     -1.283389    -1.315444       0  Setosa\n",
            "4     -1.021849     1.249201     -1.340227    -1.315444       0  Setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Save the fully processed dataset**"
      ],
      "metadata": {
        "id": "KPY77VmBCbLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed dataset\n",
        "processed_data.to_csv('iris_processed_standardized.csv', index=False)\n",
        "files.download('iris_processed_standardized.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5wOkJhu_CRBm",
        "outputId": "decab011-0b33-434e-b949-aa2e517ca789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55872619-549b-4f0b-8386-b54337137fdc\", \"iris_processed_standardized.csv\", 13525)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}